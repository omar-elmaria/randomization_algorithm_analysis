{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud import bigquery_storage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pingouin as pg\n",
    "import datetime as dt\n",
    "from datetime import datetime, timedelta\n",
    "import uuid\n",
    "import scipy.stats\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1: Define some input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_length = 28\n",
    "sb_window_size = 3\n",
    "# Define the list of KPIs\n",
    "col_list = [\n",
    "    'actual_df_paid_by_customer', 'gfv_local', 'gmv_local', 'commission_local', 'joker_vendor_fee_local', # Customer KPIs (1)\n",
    "    'sof_local', 'service_fee_local', 'revenue_local', 'delivery_costs_local', 'gross_profit_local', # Customer KPIs (2)\n",
    "    'dps_mean_delay', 'delivery_distance_m', 'actual_DT' # Logistics KPIs\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Instantiate a BQ client and run the SQL query that pulls the historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client(project=\"logistics-data-staging-flat\")\n",
    "bqstorage_client = bigquery_storage.BigQueryReadClient()\n",
    "\n",
    "with open(\"sql_queries.sql\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    query = f.read()\n",
    "    f.close()\n",
    "\n",
    "client.query(query=query).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1422904/1422904 [01:07<00:00, 21035.21rows/s]\n"
     ]
    }
   ],
   "source": [
    "# Pull the data from the final table generated by the query\n",
    "df = client.query(\"\"\"SELECT * FROM `dh-logistics-product-ops.pricing.ab_test_individual_orders_augmented_randomization_algo_analysis`\"\"\").result().to_dataframe(bqstorage_client=bqstorage_client, progress_bar_type=\"tqdm\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1: Define a list of dictionaries containing the entity IDs, ASA IDs, and zone names that will be used in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_asa_zone_dict = [\n",
    "    # SG\n",
    "    {\"entity_id\": \"FP_SG\", \"asa_id\": 559, \"zone_names\": [\"Bukitpanjang\", \"Jurongwest\", \"Woodlands\"], \"zone_group_identifier\": \"zg_1\"},\n",
    "    {\"entity_id\": \"FP_SG\", \"asa_id\": 560, \"zone_names\": [\"Far_east\", \"Jurong east\"], \"zone_group_identifier\": \"zg_2\"},\n",
    "\n",
    "    # HK\n",
    "    {\"entity_id\": \"FP_HK\", \"asa_id\": 402, \"zone_names\": [\"To kwa wan rider\", \"Kowloon city rider\", \"Lai chi kok rider\"], \"zone_group_identifier\": \"zg_3\"},\n",
    "    {\"entity_id\": \"FP_HK\", \"asa_id\": 406, \"zone_names\": [\"Ma liu shui rider\", \"Kwai chung rider\", \"Sai kung rider\", \"Sheung shui rider\", \"Tai po rider\", \"Tai wai rider\", \"Tin shui wai rider\", \"Tsing yi rider\", \"Tsuen wan rider\", \"Tuen mun rider\", \"Tun chung rider\", \"Yuen long rider\"], \"zone_group_identifier\": \"zg_4\"},\n",
    "    {\"entity_id\": \"FP_HK\", \"asa_id\": 398, \"zone_names\": [\"Admiralty cwb rider\", \"Happy valley cwb rider\", \"Kennedy town rider\", \"Quarry bay rider\"], \"zone_group_identifier\": \"zg_5\"},\n",
    "\n",
    "    # PH\n",
    "    {\"entity_id\": \"FP_PH\", \"asa_id\": 496, \"zone_names\": [\"South alabang atc\", \"Paranaque\", \"North Ias pinas\", \"North alabang atc\", \"Bf homes\"], \"zone_group_identifier\": \"zg_6\"},\n",
    "    {\"entity_id\": \"FP_PH\", \"asa_id\": 525, \"zone_names\": [\"Bacoor north\", \"Tagaytay\", \"Dasmarinas\", \"Imus\"], \"zone_group_identifier\": \"zg_7\"},\n",
    "    {\"entity_id\": \"FP_PH\", \"asa_id\": 528, \"zone_names\": [\"Antipolo north\", \"Malabon\", \"Sjdm\", \"Valenzuela\"], \"zone_group_identifier\": \"zg_8\"},\n",
    "    {\"entity_id\": \"FP_PH\", \"asa_id\": 508, \"zone_names\": [\"Makati\", \"Pasay\"], \"zone_group_identifier\": \"zg_9\"}\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2: Create a new data frame with the combinations stipulated in the dictionary above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = []\n",
    "for i in entity_asa_zone_dict:\n",
    "    df_iter = df[(df[\"entity_id\"] == i[\"entity_id\"]) & (df[\"asa_id\"] == i[\"asa_id\"]) & (df[\"zone_name\"].isin(i[\"zone_names\"]))]\n",
    "    df_iter[\"zone_group_identifier\"] = i[\"zone_group_identifier\"]\n",
    "    df_reduced.append(df_iter)\n",
    "\n",
    "# Convert df_reduced to a dataframe\n",
    "df_reduced = pd.concat(df_reduced)\n",
    "\n",
    "# Add a new field to df_reduced showing a different format of \"dps_sessionid_created_at_utc\". We want to display the format followed by DPS, which is \"%Y-%m-%dT%H:%M:%SZ\"\n",
    "df_reduced[\"dps_sessionid_created_at_utc_formatted\"] = df_reduced[\"dps_sessionid_created_at_utc\"]\\\n",
    "    .apply(lambda x: pd.to_datetime(dt.datetime.strftime(x, \"%Y-%m-%dT%H:%M:%SZ\")))\n",
    "\n",
    "df_reduced.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The shell script that runs the randomization algorithm needs the starting time of the experiment as one of its input\n",
    "# We define that as the minimum dps_session_start_timestamp per zone_group_identifier\n",
    "df_min_max_dps_session_start_ts = df_reduced.groupby([\"entity_id\", \"zone_group_identifier\"])[\"dps_sessionid_created_at_utc_formatted\"]\\\n",
    "    .agg([\"min\", \"max\"])\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={\"min\": \"min_dps_session_start_ts\", \"max\": \"max_dps_session_start_ts\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1: Create a function that takes the zone_group_identifier and creates a CSV file called input_{zg_identifier}. This file contains the details necessary to run the randomization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_csv_func(zg_identifier):\n",
    "    df_stg = df_reduced[df_reduced[\"zone_group_identifier\"] == zg_identifier][[\"platform_order_code\", \"zone_id\", \"dps_sessionid_created_at_utc_formatted\"]]\\\n",
    "        .sort_values(\"dps_sessionid_created_at_utc_formatted\")\\\n",
    "        .reset_index(drop=True)\n",
    "    df_stg[\"dps_sessionid_created_at_utc_formatted\"] = df_stg[\"dps_sessionid_created_at_utc_formatted\"].apply(lambda x: str(x))\n",
    "    df_stg.to_csv(f\"input.csv\", index=False, header=False, date_format=\"str\")\n",
    "\n",
    "# Invoke the function that creates the input file. Keep in mind that this overwrites the already existing input.csv file\n",
    "input_csv_func(zg_identifier=\"zg_1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.2: Convert the CSV file to UNIX format and run the variant allocation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dos2unix: converting file input.csv to Unix format...\n"
     ]
    }
   ],
   "source": [
    "%%script \"C:/Program Files/Git/bin/bash.exe\"\n",
    "dos2unix input.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: 28115\n",
      "salt: DB0720FD-326E-407F-9EA2-512BF8154DDE\n",
      "Switchback parameters are valid, starting experiment..\n",
      "Allocation is complete. Results are available in output.csv file\n"
     ]
    }
   ],
   "source": [
    "%%script \"C:/Program Files/Git/bin/bash.exe\"\n",
    "./run-allocation.sh -w 3.0 -v 3 -t 2023-01-01T00:48:04Z -k 28115 -s DB0720FD-326E-407F-9EA2-512BF8154DDE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create a function that gives a random UUID to each time interval. Note: This part will be removed once the UUID functionality is incorporated in the JS function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr_interval_date_func_random(zg_id, test_length, sb_interval, zone_name_list: list):\n",
    "    min_timestamp_zg_id = df_min_max_dps_session_start_ts[df_min_max_dps_session_start_ts[\"zone_group_identifier\"] == zg_id].reset_index()[\"min_dps_session_start_ts\"][0]\n",
    "    num_time_units = int((24 / sb_interval) * test_length)\n",
    "\n",
    "    # Create an array of timestamps separated by the switchback window size\n",
    "    df_mapping = [min_timestamp_zg_id] # Decalre teh df_mapping variable as a list with the first value being min_timestamp_zg_id\n",
    "    timestamp_iter = min_timestamp_zg_id # Initialize the timestamp_iter with min_timestamp_zg_id\n",
    "    for i in range(1, num_time_units):\n",
    "        df_mapping.append(timestamp_iter + timedelta(hours = 3))\n",
    "        timestamp_iter = timestamp_iter + timedelta(hours=3) # Update the \n",
    "    df_mapping = pd.DataFrame(df_mapping, columns=[\"dps_session_created_at\"]) # Convert the list to a data frame\n",
    "\n",
    "    # Create new columns\n",
    "    df_mapping[\"dps_session_created_date\"] = df_mapping[\"dps_session_created_at\"].apply(lambda x: pd.to_datetime(x.date()))\n",
    "    df_mapping[\"dps_session_created_at_interval\"] = pd.cut(df_mapping[\"dps_session_created_at\"], bins=num_time_units, right=False)\n",
    "    df_mapping[\"common_key\"] = 0\n",
    "\n",
    "    # Create a new data frame containing the zones in the zone group ID\n",
    "    df_zone_id = pd.DataFrame({\"zone_name\": zone_name_list, \"common_key\": 0})\n",
    "    df_mapping = pd.merge(left=df_mapping, right=df_zone_id, how=\"outer\", on=\"common_key\")\n",
    "    df_mapping.drop(\"common_key\", axis=1, inplace=True)\n",
    "    \n",
    "    rnd_id_list = [] # Create the full list that the rng.choice would choose from\n",
    "    for i in range(1, len(df_mapping) + 1):\n",
    "        rnd_id_list.append(uuid.uuid4())\n",
    "\n",
    "    rng = np.random.default_rng()\n",
    "    df_mapping['time_zone_unit_id'] = rng.choice(rnd_id_list, replace = False, axis = 0, size = len(df_mapping))\n",
    "    return df_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dps_session_created_at</th>\n",
       "      <th>dps_session_created_date</th>\n",
       "      <th>dps_session_created_at_interval</th>\n",
       "      <th>zone_name</th>\n",
       "      <th>time_zone_unit_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01 00:48:04+00:00</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>[2023-01-01 00:48:04, 2023-01-01 03:47:15.7857...</td>\n",
       "      <td>Jurongwest</td>\n",
       "      <td>84ec420d-7ff7-4b33-882c-efc183b1cbb9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01 00:48:04+00:00</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>[2023-01-01 00:48:04, 2023-01-01 03:47:15.7857...</td>\n",
       "      <td>Woodlands</td>\n",
       "      <td>62da6476-0ae3-495d-843d-f10c50fe4455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01 00:48:04+00:00</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>[2023-01-01 00:48:04, 2023-01-01 03:47:15.7857...</td>\n",
       "      <td>Bukitpanjang</td>\n",
       "      <td>b920b1e5-7816-493f-a672-e62eb5caa87c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-01 03:48:04+00:00</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>[2023-01-01 03:47:15.785714176, 2023-01-01 06:...</td>\n",
       "      <td>Jurongwest</td>\n",
       "      <td>c49d4272-c143-497d-a329-0a921e9b588c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01 03:48:04+00:00</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>[2023-01-01 03:47:15.785714176, 2023-01-01 06:...</td>\n",
       "      <td>Woodlands</td>\n",
       "      <td>fa791024-3d3d-4cf4-8b20-6e2a01d26661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-01 03:48:04+00:00</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>[2023-01-01 03:47:15.785714176, 2023-01-01 06:...</td>\n",
       "      <td>Bukitpanjang</td>\n",
       "      <td>3ec6d74d-f5aa-465e-9921-67d1497c37ec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-01 06:48:04+00:00</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>[2023-01-01 06:46:27.571428608, 2023-01-01 09:...</td>\n",
       "      <td>Jurongwest</td>\n",
       "      <td>0e5fa4b1-f5cc-4774-893a-63da6afde383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-01 06:48:04+00:00</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>[2023-01-01 06:46:27.571428608, 2023-01-01 09:...</td>\n",
       "      <td>Woodlands</td>\n",
       "      <td>d6593659-514c-4c8e-945e-1bad9a1526ec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-01-01 06:48:04+00:00</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>[2023-01-01 06:46:27.571428608, 2023-01-01 09:...</td>\n",
       "      <td>Bukitpanjang</td>\n",
       "      <td>eab84d22-d9db-4d7e-a7d3-06a958790631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-01-01 09:48:04+00:00</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>[2023-01-01 09:45:39.357142784, 2023-01-01 12:...</td>\n",
       "      <td>Jurongwest</td>\n",
       "      <td>60a77859-4a8b-42ef-ac64-a1c9684e44ba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dps_session_created_at dps_session_created_date  \\\n",
       "0 2023-01-01 00:48:04+00:00               2023-01-01   \n",
       "1 2023-01-01 00:48:04+00:00               2023-01-01   \n",
       "2 2023-01-01 00:48:04+00:00               2023-01-01   \n",
       "3 2023-01-01 03:48:04+00:00               2023-01-01   \n",
       "4 2023-01-01 03:48:04+00:00               2023-01-01   \n",
       "5 2023-01-01 03:48:04+00:00               2023-01-01   \n",
       "6 2023-01-01 06:48:04+00:00               2023-01-01   \n",
       "7 2023-01-01 06:48:04+00:00               2023-01-01   \n",
       "8 2023-01-01 06:48:04+00:00               2023-01-01   \n",
       "9 2023-01-01 09:48:04+00:00               2023-01-01   \n",
       "\n",
       "                     dps_session_created_at_interval     zone_name  \\\n",
       "0  [2023-01-01 00:48:04, 2023-01-01 03:47:15.7857...    Jurongwest   \n",
       "1  [2023-01-01 00:48:04, 2023-01-01 03:47:15.7857...     Woodlands   \n",
       "2  [2023-01-01 00:48:04, 2023-01-01 03:47:15.7857...  Bukitpanjang   \n",
       "3  [2023-01-01 03:47:15.785714176, 2023-01-01 06:...    Jurongwest   \n",
       "4  [2023-01-01 03:47:15.785714176, 2023-01-01 06:...     Woodlands   \n",
       "5  [2023-01-01 03:47:15.785714176, 2023-01-01 06:...  Bukitpanjang   \n",
       "6  [2023-01-01 06:46:27.571428608, 2023-01-01 09:...    Jurongwest   \n",
       "7  [2023-01-01 06:46:27.571428608, 2023-01-01 09:...     Woodlands   \n",
       "8  [2023-01-01 06:46:27.571428608, 2023-01-01 09:...  Bukitpanjang   \n",
       "9  [2023-01-01 09:45:39.357142784, 2023-01-01 12:...    Jurongwest   \n",
       "\n",
       "                      time_zone_unit_id  \n",
       "0  84ec420d-7ff7-4b33-882c-efc183b1cbb9  \n",
       "1  62da6476-0ae3-495d-843d-f10c50fe4455  \n",
       "2  b920b1e5-7816-493f-a672-e62eb5caa87c  \n",
       "3  c49d4272-c143-497d-a329-0a921e9b588c  \n",
       "4  fa791024-3d3d-4cf4-8b20-6e2a01d26661  \n",
       "5  3ec6d74d-f5aa-465e-9921-67d1497c37ec  \n",
       "6  0e5fa4b1-f5cc-4774-893a-63da6afde383  \n",
       "7  d6593659-514c-4c8e-945e-1bad9a1526ec  \n",
       "8  eab84d22-d9db-4d7e-a7d3-06a958790631  \n",
       "9  60a77859-4a8b-42ef-ac64-a1c9684e44ba  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_interval_date_func_random(zg_id=\"zg_1\", test_length=exp_length, sb_interval=sb_window_size, zone_name_list=df_analysis[\"zone_name\"].unique()).head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.1: After the output.csv file is created, retrieve the variants from the output.csv file and join them to df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variants = pd.read_csv(\"output.csv\")\n",
    "df_analysis = df_reduced[df_reduced[\"zone_group_identifier\"] == \"zg_1\"].copy() # Create a copy of df_reduced just for the zg_id being analysed\n",
    "df_analysis = pd.merge(left=df_analysis, right=df_variants, how=\"left\", left_on=\"platform_order_code\", right_on=\"OrderID\")\n",
    "df_analysis.drop(\"OrderID\", axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.2: Do some extra operations on df_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column indicating the week number\n",
    "df_analysis[\"dps_session_created_date\"] = df_analysis[\"dps_sessionid_created_at_utc_formatted\"].apply(lambda x: pd.to_datetime(datetime.date(x)))\n",
    "\n",
    "# Change the KPI columns to numeric\n",
    "df_analysis[col_list] = df_analysis[col_list].apply(lambda x: pd.to_numeric(x))\n",
    "\n",
    "# Create a conditions list\n",
    "start_date = df_analysis[\"created_date_local\"].min()\n",
    "conditions = [\n",
    "    (df_analysis[\"created_date_local\"] >= start_date) & (df_analysis[\"created_date_local\"] <= start_date + timedelta(6)),\n",
    "    (df_analysis[\"created_date_local\"] >= start_date + timedelta(7)) & (df_analysis[\"created_date_local\"] <= start_date + timedelta(13)),\n",
    "    (df_analysis[\"created_date_local\"] >= start_date + timedelta(14)) & (df_analysis[\"created_date_local\"] <= start_date + timedelta(20)),\n",
    "    (df_analysis[\"created_date_local\"] >= start_date + timedelta(21)) & (df_analysis[\"created_date_local\"] <= start_date + timedelta(27)),\n",
    "]\n",
    "\n",
    "df_analysis[\"week_num\"] = np.select(condlist=conditions, choicelist=[\"week_1\", \"week_2\", \"week_3\", \"week_4\"])\n",
    "\n",
    "# Create the data frame containing the random UUIDs for each time interval\n",
    "df_mapping = hr_interval_date_func_random(zg_id=\"zg_1\", test_length=exp_length, sb_interval=sb_window_size, zone_name_list=df_analysis[\"zone_name\"].unique())\n",
    "\n",
    "# Create a function that returns the right hr_interval from df_mapping for any given number\n",
    "def check_right_interval(num, col):\n",
    "    for i in col:\n",
    "        if num in i:\n",
    "            return i\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "# Get the right interval using the \"check_right_interval\" function\n",
    "df_analysis['dps_session_created_at_interval'] = df_analysis\\\n",
    "    .apply(lambda x: check_right_interval(x['dps_sessionid_created_at_utc_formatted'], df_mapping['dps_session_created_at_interval']), axis = 1)\n",
    "\n",
    "# Filter df_analysis based on exp_length\n",
    "df_analysis = df_analysis[df_analysis[\"day_num\"] <= exp_length]\n",
    "\n",
    "# Merge the random UUIDs with df_analysis. Note: This part will be removed once the UUID functionality is incorporated in the JS function\n",
    "df_analysis = pd.merge(left = df_analysis, right = df_mapping, how = 'left', on = [\"dps_session_created_at_interval\", \"zone_name\", \"dps_session_created_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the \"total\" metrics and rename the column label to \"df_per_order_metrics\"\n",
    "df_analysis_tot = round(df_analysis.groupby([\"time_zone_unit_id\", \"Variant\"])[col_list[:-3]].sum(), 2)\n",
    "df_analysis_tot['order_count'] = df_analysis.groupby([\"time_zone_unit_id\", \"Variant\"])['platform_order_code'].nunique()\n",
    "df_analysis_tot = df_analysis_tot.rename_axis(['df_tot_metrics'], axis = 1)\n",
    "\n",
    "\n",
    "# Calculate the \"total\" metrics and rename the column label to \"df_per_order_metrics\"\n",
    "df_analysis_per_order_cust_kpis = df_analysis_tot.copy()\n",
    "\n",
    "for iter_col in df_analysis_per_order_cust_kpis.columns[:-1]:\n",
    "    df_analysis_per_order_cust_kpis[iter_col] = round(df_analysis_per_order_cust_kpis[iter_col] / df_analysis_per_order_cust_kpis['order_count'], 4)\n",
    "\n",
    "df_analysis_per_order_log_kpis = round(df_analysis.groupby([\"time_zone_unit_id\", \"Variant\"])[col_list[-3:]].mean(), 2) \n",
    "df_analysis_per_order = pd.concat([df_analysis_per_order_cust_kpis, df_analysis_per_order_log_kpis], axis = 1)\n",
    "df_analysis_per_order = df_analysis_per_order.rename_axis(['df_per_order_metrics'], axis = 1)\n",
    "\n",
    "# Reset the indices of the \n",
    "df_analysis_tot = df_analysis_tot.reset_index()\n",
    "df_analysis_per_order = df_analysis_per_order.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2997"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.welch_anova(dv=\"actual_df_paid_by_customer\", between=\"Variant\", data=df_analysis_tot)[\"p-unc\"].iloc[0].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>df_per_order_metrics</th>\n",
       "      <th>time_zone_unit_id</th>\n",
       "      <th>Variant</th>\n",
       "      <th>actual_df_paid_by_customer</th>\n",
       "      <th>revenue_local</th>\n",
       "      <th>delivery_costs_local</th>\n",
       "      <th>gross_profit_local</th>\n",
       "      <th>order_count</th>\n",
       "      <th>delivery_distance_m</th>\n",
       "      <th>actual_DT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001d931c-f693-4c55-930f-c094af3487cf</td>\n",
       "      <td>Variant1</td>\n",
       "      <td>10.9900</td>\n",
       "      <td>22.7800</td>\n",
       "      <td>14.5500</td>\n",
       "      <td>8.2300</td>\n",
       "      <td>1</td>\n",
       "      <td>8085.00</td>\n",
       "      <td>83.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0161361c-c00b-4b76-8f36-fffb4032a676</td>\n",
       "      <td>Variant1</td>\n",
       "      <td>4.6900</td>\n",
       "      <td>10.6500</td>\n",
       "      <td>7.5400</td>\n",
       "      <td>3.1100</td>\n",
       "      <td>1</td>\n",
       "      <td>2401.00</td>\n",
       "      <td>64.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0164a2ca-c344-4000-b29e-b48e80e4b2a0</td>\n",
       "      <td>Variant1</td>\n",
       "      <td>3.8900</td>\n",
       "      <td>19.8600</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>12.1100</td>\n",
       "      <td>2</td>\n",
       "      <td>3905.00</td>\n",
       "      <td>31.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02071705-8063-49ea-84c3-6f18ae9a8973</td>\n",
       "      <td>Variant0</td>\n",
       "      <td>5.4400</td>\n",
       "      <td>26.0600</td>\n",
       "      <td>10.5800</td>\n",
       "      <td>15.4800</td>\n",
       "      <td>4</td>\n",
       "      <td>4850.00</td>\n",
       "      <td>34.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02b51ad1-4af1-4c00-bb19-ced160309b5c</td>\n",
       "      <td>Variant0</td>\n",
       "      <td>6.2043</td>\n",
       "      <td>17.2186</td>\n",
       "      <td>10.9829</td>\n",
       "      <td>6.2357</td>\n",
       "      <td>7</td>\n",
       "      <td>3744.57</td>\n",
       "      <td>33.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>fc2cf71f-6f95-4765-832a-df5dec30bec4</td>\n",
       "      <td>Variant1</td>\n",
       "      <td>7.1900</td>\n",
       "      <td>15.0450</td>\n",
       "      <td>14.0200</td>\n",
       "      <td>1.0250</td>\n",
       "      <td>2</td>\n",
       "      <td>5396.50</td>\n",
       "      <td>55.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>fe847d6a-4e12-4141-b476-121816931032</td>\n",
       "      <td>Variant1</td>\n",
       "      <td>4.1900</td>\n",
       "      <td>14.1300</td>\n",
       "      <td>8.0700</td>\n",
       "      <td>6.0600</td>\n",
       "      <td>1</td>\n",
       "      <td>1780.00</td>\n",
       "      <td>25.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>fed2a0c2-cfdd-46b1-8e85-faa012966db0</td>\n",
       "      <td>Variant1</td>\n",
       "      <td>4.4900</td>\n",
       "      <td>12.4888</td>\n",
       "      <td>10.0025</td>\n",
       "      <td>2.4862</td>\n",
       "      <td>8</td>\n",
       "      <td>4184.50</td>\n",
       "      <td>27.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>ff0cf02b-e7af-43d1-a4ec-af0540b64f92</td>\n",
       "      <td>Variant2</td>\n",
       "      <td>6.7233</td>\n",
       "      <td>12.2733</td>\n",
       "      <td>9.8733</td>\n",
       "      <td>2.4000</td>\n",
       "      <td>3</td>\n",
       "      <td>5675.00</td>\n",
       "      <td>28.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>ff4940f2-23cc-4442-86b2-2f0710e1ee53</td>\n",
       "      <td>Variant2</td>\n",
       "      <td>4.2200</td>\n",
       "      <td>14.6080</td>\n",
       "      <td>8.2500</td>\n",
       "      <td>6.3580</td>\n",
       "      <td>10</td>\n",
       "      <td>3167.80</td>\n",
       "      <td>32.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "df_per_order_metrics                     time_zone_unit_id   Variant  \\\n",
       "0                     001d931c-f693-4c55-930f-c094af3487cf  Variant1   \n",
       "1                     0161361c-c00b-4b76-8f36-fffb4032a676  Variant1   \n",
       "2                     0164a2ca-c344-4000-b29e-b48e80e4b2a0  Variant1   \n",
       "3                     02071705-8063-49ea-84c3-6f18ae9a8973  Variant0   \n",
       "4                     02b51ad1-4af1-4c00-bb19-ced160309b5c  Variant0   \n",
       "..                                                     ...       ...   \n",
       "300                   fc2cf71f-6f95-4765-832a-df5dec30bec4  Variant1   \n",
       "301                   fe847d6a-4e12-4141-b476-121816931032  Variant1   \n",
       "302                   fed2a0c2-cfdd-46b1-8e85-faa012966db0  Variant1   \n",
       "303                   ff0cf02b-e7af-43d1-a4ec-af0540b64f92  Variant2   \n",
       "304                   ff4940f2-23cc-4442-86b2-2f0710e1ee53  Variant2   \n",
       "\n",
       "df_per_order_metrics  actual_df_paid_by_customer  revenue_local  \\\n",
       "0                                        10.9900        22.7800   \n",
       "1                                         4.6900        10.6500   \n",
       "2                                         3.8900        19.8600   \n",
       "3                                         5.4400        26.0600   \n",
       "4                                         6.2043        17.2186   \n",
       "..                                           ...            ...   \n",
       "300                                       7.1900        15.0450   \n",
       "301                                       4.1900        14.1300   \n",
       "302                                       4.4900        12.4888   \n",
       "303                                       6.7233        12.2733   \n",
       "304                                       4.2200        14.6080   \n",
       "\n",
       "df_per_order_metrics  delivery_costs_local  gross_profit_local  order_count  \\\n",
       "0                                  14.5500              8.2300            1   \n",
       "1                                   7.5400              3.1100            1   \n",
       "2                                   7.7500             12.1100            2   \n",
       "3                                  10.5800             15.4800            4   \n",
       "4                                  10.9829              6.2357            7   \n",
       "..                                     ...                 ...          ...   \n",
       "300                                14.0200              1.0250            2   \n",
       "301                                 8.0700              6.0600            1   \n",
       "302                                10.0025              2.4862            8   \n",
       "303                                 9.8733              2.4000            3   \n",
       "304                                 8.2500              6.3580           10   \n",
       "\n",
       "df_per_order_metrics  delivery_distance_m  actual_DT  \n",
       "0                                 8085.00      83.68  \n",
       "1                                 2401.00      64.23  \n",
       "2                                 3905.00      31.96  \n",
       "3                                 4850.00      34.51  \n",
       "4                                 3744.57      33.46  \n",
       "..                                    ...        ...  \n",
       "300                               5396.50      55.92  \n",
       "301                               1780.00      25.55  \n",
       "302                               4184.50      27.46  \n",
       "303                               5675.00      28.31  \n",
       "304                               3167.80      32.08  \n",
       "\n",
       "[305 rows x 9 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Calculate the p-values using the Welch's t-test\n",
    "pval_dict = {}\n",
    "df_pval_final_list = []\n",
    "\n",
    "for iter_col in df_analysis_per_order.columns[2:]:\n",
    "    anova_pval_tot = pg.welch_anova(dv=iter_col, between=\"Variant\", data=df_analysis_tot)[\"p-unc\"].iloc[0].round(4)\n",
    "    anova_pval_per_order = pg.welch_anova(dv=iter_col, between=\"Variant\", data=df_analysis_per_order)[\"p-unc\"].iloc[0].round(4)\n",
    "\n",
    "df_pval_final_list.append(pval_dict)\n",
    "\n",
    "# Convert the p-values to a data frame\n",
    "df_pval_final_tbl = pd.DataFrame(df_pval_final_list)\\\n",
    "    .assign(entity_id = entity_id, zone_name = zone_name)\\\n",
    "    .set_index(['entity_id', 'zone_name'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_sb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14e010e4cd1c1ecfc2a757c09121a44deab645fe879881bec23ed2eed3f5394d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
